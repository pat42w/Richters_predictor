{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Richter's predicter entry\n",
    "Below is the basis for my entry to the Richters predicter open competition hosted by Drivendatausing Catboost.\n",
    "\n",
    "https://www.drivendata.org/competitions/57/nepal-earthquake/    \n",
    "\n",
    "\"\"\"   \n",
    "Based on aspects of building location and construction, your goal is to predict the level of damage to buildings caused by the 2015 Gorkha earthquake in Nepal.\n",
    "\n",
    "This is an intermediate-level practice competition.\n",
    "\n",
    "The data was collected through surveys by Kathmandu Living Labs and the Central Bureau of Statistics, which works under the National Planning Commission Secretariat of Nepal. This survey is one of the largest post-disaster datasets ever collected, containing valuable information on earthquake impacts, household conditions, and socio-economic-demographic statistics.   \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### Patrickwalsh1995@gmail.com\n",
    "### https://github.com/pat42w/\n",
    "### https://www.drivendata.org/users/PatW42/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "pd.set_option('display.max_columns', 38)\n",
    "\n",
    "###Update this \n",
    "DATA_DIR = \"C:/Users/YOUR_NAME/Desktop/Richter's Predictor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data downloaded from https://www.drivendata.org/competitions/57/nepal-earthquake/data/\n",
    "train_values = pd.read_csv(DATA_DIR +'/train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR +'/train_labels.csv', index_col='building_id')\n",
    "\n",
    "test_values = pd.read_csv(DATA_DIR+'/test_values.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset Profile\n",
    "I have found using this very useful to get to grips with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile=train_values.join(train_labels)\n",
    "train_profile=df_profile.profile_report(title=\"Richter's Train Dataset Pandas profile\")\n",
    "\n",
    "#This is a html file and can be saved and opeded in another tab\n",
    "#train_profile.to_file(output_file=DATA_DIR+\"/Richter's Train Dataset Pandas profile.html\") \n",
    "\n",
    "train_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_profile=test_values.profile_report(title=\"Richter's Test Dataset Pandas profile\")\n",
    "#This is a html file and can be saved and opeded in another tab\n",
    "#test_profile.to_file(output_file=DATA_DIR+\"/Richter's Test Dataset Pandas profile.html\")\n",
    "test_profile"
   ]
  },
  {
   "source": [
    "## Further explore the data & show any imediate corrolations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_labels.damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heat map\n",
    "sns.heatmap(train_values.join(train_labels).corr(), annot=False, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_values.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(format('How to find optimal parameters for CatBoost using GridSearchCV for Classification','*^82'))   \n",
    "\n",
    "# load libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Split the training data set\n",
    "X = train_values; y = train_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "print('Data loaded')\n",
    "\n",
    "#Initialise the catboost classifier, if you have no GPU on your machine you can remove task_type=\"GPU\" \n",
    "model = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols)\n",
    "\n",
    "#Choose parameters to test here\n",
    "parameters = {'depth':[2,4,6,8,10,12],\n",
    "            'iterations':[10,100,500,1000,5000],\n",
    "            'learning_rate':[0.02,0.05,0.06,0.07], \n",
    "            'l2_leaf_reg':[3,5,7,9],\n",
    "            'border_count':[11,13,15,17]}\n",
    "print('Paramaters defined')\n",
    "\n",
    "#Initialise the Gridsearch, cv is set to 2 for speed.\n",
    "randm = GridSearchCV(estimator=model, param_grid = parameters,cv = 2)\n",
    "randm.fit(X_train, y_train)\n",
    "\n",
    "# Results from Random Search\n",
    "print(\"\\n========================================================\")\n",
    "print(\" Results from Random Search \" )\n",
    "print(\"========================================================\")    \n",
    "\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "      randm.best_estimator_)\n",
    "\n",
    "print(\"\\n The best score across ALL searched params:\\n\",\n",
    "      randm.best_score_)\n",
    "\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "      randm.best_params_)\n",
    "\n",
    "print(\"\\n ========================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"Resample the train test split & try these parameters set\")\n",
    "X = train_values; y = train_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "#input best params here from randm.best_params_\n",
    "model = CatBoostClassifier(eval_metric='TotalF1',random_seed=42, task_type=\"GPU\",cat_features=cat_cols,\n",
    "                           depth=5, iterations=500 ,learning_rate=0.01,l2_leaf_reg=9,\n",
    "                           border_count=10)\n",
    "model.fit(X_train, y_train)\n",
    "preds=model.predict(X_test)\n",
    "\n",
    "#f1 score is the metric used in the competition\n",
    "accuracy=f1_score(y_test,preds,average='micro')\n",
    "print(\"Score on test set\")\n",
    "print(\"\\n ========================================================\")\n",
    "print(accuracy)"
   ]
  },
  {
   "source": [
    "### Prep the test set & get predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_csv(DATA_DIR+'/test_values.csv', index_col='building_id')\n",
    "test_values=test_values.drop(columns=['has_secondary_use_institution',\n",
    "                           'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "                           'has_secondary_use_use_police', 'has_secondary_use_other',\n",
    "                          'has_secondary_use_health_post', 'has_secondary_use_gov_office'])\n",
    "                          \n",
    "\n",
    "predictions = model.predict(test_values)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the predictions are in teh correct submission format\n",
    "submission_format = pd.read_csv(DATA_DIR+'/submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission['damage_grade'] =my_submission['damage_grade'].astype(int)\n",
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get feature importances and graph, could look further into thesee to improve the model further\n",
    "df_importances=pd.DataFrame(train_values.columns)\n",
    "df_importances['importances']=model.feature_importances_\n",
    "df_importances.plot.bar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}