{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patrickwalsh1995@gmail.com\n",
    "### https://www.drivendata.org/users/PatW42/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import catboost as cb\n",
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "pd.set_option('display.max_columns', 38)\n",
    "DATA_DIR = \"C:/Users/YOUR_NAME/Desktop/Richter's Predictor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = pd.read_csv(DATA_DIR +'/train_values.csv', index_col='building_id')\n",
    "train_labels = pd.read_csv(DATA_DIR +'/train_labels.csv', index_col='building_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_profile=train_values.join(train_labels)\n",
    "train_profile=df_profile.profile_report(title=\"Richter's Train Dataset Pandas profile\")\n",
    "train_profile.to_file(output_file=DATA_DIR+\"/Richter's Train Dataset Pandas profile.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_csv(DATA_DIR+'/test_values.csv', index_col='building_id')\n",
    "test_profile=test_values.profile_report(title=\"Richter's Test Dataset Pandas profile\")\n",
    "test_profile.to_file(output_file=DATA_DIR+\"/Richter's Test Dataset Pandas profile.html\")\n",
    "test_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_labels.damage_grade\n",
    "             .value_counts()\n",
    "             .sort_index()\n",
    "             .plot.bar(title=\"Number of Buildings with Each Damage Grade\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation heat map\n",
    "sns.heatmap(train_values.join(train_labels).corr(), annot=False, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols=['geo_level_1_id','geo_level_2_id','geo_level_3_id','land_surface_condition', 'foundation_type', 'roof_type',\n",
    "       'ground_floor_type', 'other_floor_type', 'position',\n",
    "       'plan_configuration', 'legal_ownership_status','count_floors_pre_eq', 'has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "       'has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick',\n",
    "       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "       'has_superstructure_rc_engineered', 'has_superstructure_other',\n",
    "       'legal_ownership_status', 'has_secondary_use',\n",
    "       'has_secondary_use_agriculture', 'has_secondary_use_hotel',\n",
    "       'has_secondary_use_rental', 'has_secondary_use_institution',\n",
    "       'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "       'has_secondary_use_health_post', 'has_secondary_use_gov_office',\n",
    "       'has_secondary_use_use_police', 'has_secondary_use_other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_values.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for preprocessing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# for combining the preprocess with model training\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# for optimizing the hyperparameters of the pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from catboost import Pool, CatBoostClassifier, cv\n",
    "import catboost\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Snippet_200(): \n",
    "    print()\n",
    "    print(format('How to find optimal parameters for CatBoost using GridSearchCV for Classification','*^82'))    \n",
    "    # load libraries\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from catboost import CatBoostClassifier\n",
    "\n",
    "    # load the iris datasets\n",
    "    X = train_values; y = train_labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "    print('Data loaded')\n",
    "    model = CatBoostClassifier(eval_metric='TotalF1', task_type=\"GPU\",cat_features=cat_cols)\n",
    "    \n",
    "    parameters = {'depth':[2,4,6,8,10,12],\n",
    "                  'iterations':[10,100,500,1000,5000],\n",
    "                  'learning_rate':[0.02,0.05,0.06,0.07], \n",
    "                  'l2_leaf_reg':[3,5,7,9],\n",
    "                  'border_count':[11,13,15,17]}\n",
    "    randm = GridSearchCV(estimator=model, param_grid = parameters,cv = 2)\n",
    "    print('Paramaters defined')\n",
    "    randm.fit(X_train, y_train)\n",
    "\n",
    "    # Results from Random Search\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\" Results from Random Search \" )\n",
    "    print(\"========================================================\")    \n",
    "\n",
    "    print(\"\\n The best estimator across ALL searched params:\\n\",\n",
    "          randm.best_estimator_)\n",
    "\n",
    "    print(\"\\n The best score across ALL searched params:\\n\",\n",
    "          randm.best_score_)\n",
    "\n",
    "    print(\"\\n The best parameters across ALL searched params:\\n\",\n",
    "           randm.best_params_)\n",
    "\n",
    "    print(\"\\n ========================================================\")\n",
    "Snippet_200()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(\"Trying on test set\")\n",
    "X = train_values; y = train_labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "#input best params here\n",
    "model = CatBoostClassifier(eval_metric='TotalF1',random_seed=42, task_type=\"GPU\",cat_features=cat_cols,\n",
    "                           depth=5, iterations=500 ,learning_rate=0.01,l2_leaf_reg=9,\n",
    "                           border_count=10)\n",
    "model.fit(X_train, y_train)\n",
    "preds=model.predict(X_test)\n",
    "accuracy=f1_score(y_test,preds,average='micro')\n",
    "print(\"Score on test set\")\n",
    "print(\"\\n ========================================================\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(DATA_DIR+'/catbost.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = pd.read_csv(DATA_DIR+'/test_values.csv', index_col='building_id')\n",
    "test_values=test_values.drop(columns=['has_secondary_use_institution',\n",
    "                           'has_secondary_use_school', 'has_secondary_use_industry',\n",
    "                           'has_secondary_use_use_police', 'has_secondary_use_other',\n",
    "                          'has_secondary_use_health_post', 'has_secondary_use_gov_office'])\n",
    "                          \n",
    "\n",
    "predictions = model.predict(test_values)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = pd.read_csv(DATA_DIR+'/submission_format.csv', index_col='building_id')\n",
    "my_submission = pd.DataFrame(data=predictions,\n",
    "                             columns=submission_format.columns,\n",
    "                             index=submission_format.index)\n",
    "my_submission['damage_grade'] =my_submission['damage_grade'].astype(int)\n",
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.to_csv('tsecvsubmission.csv')\n",
    "#!head submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_importances=pd.DataFrame(train_values.columns)\n",
    "df_importances['importances']=pipe.feature_importances_\n",
    "df_importances[df_importances['importances']>0]\n",
    "#df_importances.to_csv(DATA_DIR+\"/df_importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_update=df_importances[0][df_importances['importances']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_update.to_list()\n",
    "len(selected_features_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_file = CatBoostClassifier()\n",
    "\n",
    "from_file.load_model(DATA_DIR+'/catbost.sav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
